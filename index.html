<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jianyuan Wang's Homepage</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 40px auto;
            padding: 0 20px;
            background-color: #fdfdfd;
        }
        header {
            border-bottom: 1px solid #e0e0e0;
            padding-bottom: 20px;
            margin-bottom: 40px;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
        }
        .header-text {
            flex-grow: 1;
        }
        .profile-photo {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            object-fit: cover;
            margin-right: 40px;
            background-color: #e0e0e0; /* Placeholder color */
        }
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        h2 {
            font-size: 1.8em;
            border-bottom: 1px solid #e0e0e0;
            padding-bottom: 10px;
            margin-top: 40px;
        }
        h3 {
            font-size: 1.3em;
            margin-bottom: 8px;
        }
        p, li {
            margin-bottom: 15px;
        }
        a {
            color: #007bff;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .links a {
            margin-right: 15px;
        }
        .publication {
            margin-bottom: 30px;
        }
        .publication .authors {
            margin: 5px 0;
        }
        .publication .venue {
            font-style: italic;
        }
        .publication .links a {
            margin-right: 10px;
            font-weight: bold;
        }
        .news-item {
            margin-bottom: 10px;
        }
        .meeting-section {
            text-align: center;
            padding: 30px;
            background-color: #f0f7ff;
            border: 1px solid #cce0ff;
            border-radius: 8px;
            margin-top: 40px;
            margin-bottom: 40px;
        }
        .meeting-link {
            display: inline-block;
            background-color: #007bff;
            color: #fff;
            padding: 12px 25px;
            border-radius: 5px;
            font-size: 1.1em;
            font-weight: bold;
            text-decoration: none;
            transition: background-color 0.3s ease;
        }
        .meeting-link:hover {
            background-color: #0056b3;
            text-decoration: none;
        }
        .meeting-time {
            margin-top: 15px;
            font-size: 1.1em;
            color: #555;
        }
        footer {
            text-align: center;
            margin-top: 50px;
            font-size: 0.9em;
            color: #777;
        }
    </style>
</head>
<body>

    <header>
        <!-- Add the path to your profile photo in the src attribute -->
        <img src="" alt="Profile Photo" class="profile-photo">
        <div class="header-text">
            <h1>Jianyuan Wang (王建元)</h1>
            <p>Joint PhD Student at Facebook AI Research and Visual Geometry Group (VGG), University of Oxford.</p>
            <div class="links">
                <a href="#">Email</a> /
                <a href="#">Google Scholar</a> /
                <a href="#">Twitter</a> /
                <a href="#">Github</a>
            </div>
        </div>
    </header>

    <main>
        <section id="about">
            <h2>About Me</h2>
            <p>
                Hi, I'm Jay (Jianyuan Wang, 王建元), a joint PhD student at Facebook AI Research and the Visual Geometry Group (VGG), University of Oxford. I work on computer vision with David Novotny, Christian Rupprecht, and Andrea Vedaldi. My work has been recognized with several honors, including a CVPR 2025 Best Paper Award.
            </p>
        </section>

        <section id="meeting" class="meeting-section">
            <h2>Join our CVPR 2025 Pre-meeting</h2>
            <p>Let's discuss future collaborations and exciting ideas before the main conference.</p>
            
            <!-- Replace with your meeting link -->
            <a href="https://meet.google.com/your-meeting-id" class="meeting-link" target="_blank" rel="noopener noreferrer">
                Join Google Meet
            </a>
            
            <!-- Replace with your meeting time -->
            <p class="meeting-time">
                Scheduled for: <strong>Friday, July 18, 2025, 11:00 AM (PST)</strong>
            </p>
        </section>

        <section id="news">
            <h2>News</h2>
            <div class="news-item">
                <strong>VGGT was selected for the Best Paper Award at CVPR 2025!</strong> Try our model with the <a href="#">Hugging Face demo</a>.
            </div>
            <div class="news-item">
                We have released CoTracker3, check the <a href="#">code here</a>!
            </div>
            <div class="news-item">
                VGGSfM has been published at CVPR 2024 as a Highlight!
            </div>
        </section>

        <section id="publications">
            <h2>Selected Publications</h2>
            
            <div class="publication">
                <h3>VGGT: Visual Geometry Grounded Transformer</h3>
                <p class="authors"><strong>Jianyuan Wang</strong>, Minghao Chen, Nikita Karaev, Andrea Vedaldi, Christian Rupprecht, David Novotny</p>
                <p class="venue">CVPR, 2025 (Best Paper Award)</p>
                <div class="links">
                    <a href="#">[Paper]</a> <a href="#">[Code]</a> <a href="#">[Project Page]</a> <a href="#">[Demo]</a> <a href="#">[Twitter]</a> <a href="#">[Slides]</a>
                </div>
            </div>

            <div class="publication">
                <h3>VGGSfM: Visual Geometry Grounded Deep Structure From Motion</h3>
                <p class="authors"><strong>Jianyuan Wang</strong>, Nikita Karaev, Christian Rupprecht, and David Novotny</p>
                <p class="venue">CVPR, 2024 (Highlight)</p>
                <div class="links">
                    <a href="#">[Paper]</a> <a href="#">[Project Page]</a> <a href="#">[Code]</a> <a href="#">[Demo]</a>
                </div>
            </div>

            <div class="publication">
                <h3>CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos</h3>
                <p class="authors">Nikita Karaev, Iurii Makarov, <strong>Jianyuan Wang</strong>, Natalia Neverova, Andrea Vedaldi, Christian Rupprecht</p>
                <div class="links">
                    <a href="#">[Paper]</a> <a href="#">[Project Page]</a> <a href="#">[Code]</a> <a href="#">[Demo]</a>
                </div>
            </div>

        </section>

        <section id="activities">
            <h2>Professional Activities</h2>
            <p>
                Conference Reviewer for CVPR, ICCV, ECCV, ICLR, NeurIPS, and Journal Reviewer for TPAMI.
            </p>
        </section>

    </main>

    <footer>
        <p>&copy; 2025 Jianyuan Wang</p>
    </footer>

</body>
</html>
